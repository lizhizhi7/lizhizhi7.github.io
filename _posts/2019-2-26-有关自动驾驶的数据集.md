---
layout:     post
title:      有关自动驾驶的数据集
subtitle:   自动驾驶
date:       2019-2-26
author:     Lee
header-img: img/background-selfdriving.jpg
catalog: true
tags:
    - DATA
    - Self Driving
    - Machine Learning
---

#### KITTI

**数据集介绍**
发布于2009年，KITTI数据集由德国卡尔斯鲁厄理工学院和丰田美国技术研究院联合创办，主要于算法评测。  
KITTI数据采集平台包括2个灰度摄像机，2个彩色摄像机，一个Velodyne 3D激光雷达，4个光学镜头，以及1个gps导航系统。一共细分为‘Road’, ‘City’, ‘Residential’, ‘Campus’ 和 ‘Person’五类数据；包含市区、乡村高速公路的数据，每张图像最多15辆车及30个行人，而且还包含不同程度的遮挡。整个数据集由389对立体图像和光流图，39.2公里视觉测距序列以及超过200,000 3D标注物体的图像组成。  
KITTI数据集中，目标检测包括了车辆检测、行人检测、自行车三个单项，目标追踪包括车辆追踪、行人追踪两个单项，道路分割包括urban unmarked、urban marked、urban multiple marked三个场景及前三个场景的平均值urban road等四个单项；  
数据集大小超过200G。KITTI数据集是无人驾驶学术圈使用最广泛的数据集之一了。  

[**项目主页**](http://www.cvlibs.net/datasets/kitti/index.php)  
[**参考论文链接**](http://www.webmail.cvlibs.net/publications/Geiger2012CVPR.pdf)

#### Cityscapes

发布于2016年，这是由奔驰采集的面向城市道路街景语义理解的数据集。Cityscapes专注于城市的街景主义理解，其本质就是一个计算机视觉语义分割数据集。提供的下载数据集中测试集和验证集有标注，测试集提供原图，无标注，可以把结果上传到项目主页，然后验证你算法。  
Cityscapes包含50个城市不同场景、不同背景、不同季节的街景，提供5000张精细标注的图像、20000张粗略标注的图像、30类标注物体。用PASCAL VOC标准的intersection-over-union(IoU)得分来对算法性能进行评价。

[**项目主页**](https://www.cityscapes-dataset.com/)  
[**参考论文链接**](https://arxiv.org/pdf/1604.01685.pdf)

#### ApolloScape

发布于2018年，是由百度Apollo提供的数据集。数据集中提供的图像分辨率为3384×2710，定义了共26个不同语义项的数据实例（例如汽车、自行车、行人、建筑、路灯等），而且将进一步涵盖更复杂的环境、天气和交通状况等。预计2018年数据集将完整发布包含20万帧的图像数据，包含对应的像素级标注和姿态信息。整个数据集将包含逐像素标注的高分辨率图像序列，以及场景语义分割级别的稠密3D Point的RGB视频。

[**项目主页**](http://apolloscape.auto/)

#### Mapillary

数据集介绍：共包含25,000个高分辨率图像（分为18,000个用于训练，2,000个验证，5,000个测试;平均分辨率约为900万像素），具有从200万个手动绘制的多边形的像素点注释；100个对象类别，其中60个实例特定（即枚举对象）；涵盖北美和南美，欧洲，非洲，亚洲和大洋洲的全球地理覆盖；天气条件（太阳，雨，雪，雾，阴霾）和捕获时间（黎明，白天，黄昏甚至夜晚）的高度变异性；相机传感器范围广泛，焦距变化，图像宽高比以及不同类型的相机噪音；不同的拍摄观点（从道路，人行道和越野）。

[**项目主页**](https://www.mapillary.com)

#### BDD100K

UC Berkeley 发布于2018年，这是目前来说最大规模也是最多样化的驾驶视频数据集，这些数据具有四个主要特征：大规模，多样化，在真实的街道采集，并带有时间信息。

1. 视频数据：100,000高清视频，累计时长超过1,100个小时，包含GPS位置，IMU数据和时间戳；
2. 马路目标检测数据：标注超过100,000张图像，类别包含公共汽车，交通灯，交通标志，行人，自行车，卡车，摩托车，小汽车，火车和骑手；
3. 马路目标分类数据：超过10,000张像素级道路目标标注的图片；
4. 可行驶区域：提供了100,000张带有像素级可行驶区域的图片；
5. 车道标记：多个城市的100,000张带有标注的图片。

[**项目主页**](https://bdd-data.berkeley.edu/)  
[**参考论文链接**](http://openaccess.thecvf.com/content_cvpr_2017/papers/Xu_End-To-End_Learning_of_CVPR_2017_paper.pdf)

#### Oxford RobotCar数据集

发布于2014年，是在牛津大学校园内路测，总长度1010.64公里，历时一年半所采集的数据集。在各种天气条件下进行收集，包括大雨，夜间，阳光直射和积雪，也包含施工路段行驶场景，具有非常复杂的天气场景，尤其适合评测计算机视觉算法。

[**数据集地址**](https://www.cityscapes-dataset.com/)  
[**参考论文链接**](http://robotcar-dataset.robots.ox.ac.uk/images/robotcar_ijrr.pdf)  
[**参考论文链接**](http://ori.ox.ac.uk/publications/)

#### Common.ai数据集

发布于2016年，这是一段高速公路的视频数据集，包括10个可变大小的视频片段，以20Hz的频率记录。数据除了图像之外，还记录了一些测量值，如汽车速度，加速度，转向角，GPS坐标，陀螺仪角度。

[**数据集地址**](https://github.com/commaai/research)  
[**参考论文链接**](https://arxiv.org/pdf/1608.01230.pdf)  
[**参考论文链接**](https://github.com/commaai/research0)

#### Udacity数据集

发布于2016年，Udacity是Google开设的线上教育平台，其中有自动驾驶相关线上培训，它也为其自动驾驶算法比赛专门准备了数据集。这个数据集包括在加利福尼亚和邻近城市在白天条件下行驶拍摄的图像，为1920×1200分辨率的9423帧图像，包含超过65000个标签。数据集是由CuldAd使用机器学习算法和研究员共同进行标注。  
除了车辆拍摄的图像以外，还包括车辆本身的属性和参数信息，例如经纬度、制动器、油门、转向度、转速。

[**数据集地址**](https://github.com/udacity/self-driving-car/tree/master/datasets)  
[**参考论文链接**](https://github.com/udacity/self-driving-car/tree/master/annotations)

#### CVPR Workshop

这是CVPR近几年举办的自动驾驶的workshop，由于深度学习的兴起，计算机视觉等技术被用于自动驾驶的目标检测，语义分割等领域，因此CVPR也开设了若干相关的workshop。具体的单元包括可行驶区域检测，路面的模板检测，跨域的语义分割，以及移动目标的实例级别的分割。

#### GTA数据集

英特尔的GTA的AI和这个虚拟世界给予了训练自动驾驶的可行性，一款赛车游戏《Grand Theft Auto 5》也被用来训练自动驾驶的模型，而且是一个相对廉价且适合初级人工智能探索的自动驾驶试验场。GTA是以语义分割为主，基于虚拟的游戏环境，但接近真实世界，其中几乎涵盖了各种各样的道路状况，包括山区、郊区和城市。还有各种各样的车辆，比如警车、救护车、出租车、货车等车型。

[**数据集地址**](http://www.rockstargames.com/grandtheftauto/)

#### TORCS数据集

TORCS是一种高度便携的多平台赛车模拟，被用作普通的赛车游戏，可以作为AI赛车游戏和研究平台。

[**数据集地址**](http://torcs.sourceforge.net/)

#### nuScenes数据集

发布于2018年，是由NuTonomy编辑的，并将于2019年推出最全的nuScenes数据集。采集了1000多个场景，其中包含140万幅图像、40万次激光雷达扫描（判断物体之间距离）和110万个三维边界框（用RGB相机、雷达和激光雷达组合检测的物体）。此次数据的搜集使用了6个摄像头、1个激光雷达、 5个毫米波雷达、GPS及惯导系统，包括了对于自动驾驶系统来说非常具有挑战性的复杂道路、天气条件等情况。

[**数据集地址**](https://d3u7q4379vrm7e.cloudfront.net/download)

#### CARLA

英特尔&丰田联合开源城市驾驶模拟器CARLA  
CARLA is an open-source simulator for autonomous driving research. CARLA has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, CARLA provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions. 

[**参考论文链接**](https://arxiv.org/pdf/1711.03938.pdf)


#### Carcraft

谷歌母公司Alphabet的自动驾驶子公司Waymo开发的一款软件，用来在诸如加州山景城和得克萨斯州奥斯汀等虚拟重建城市中测试无人驾驶汽车软件。该公司每天要开1287万公里的虚拟里程，专注于特别棘手的道路状况。  
在虚拟的奥斯汀、山景城、凤凰城，以及那些模拟的测试场景里，有25000辆虚拟的无人车穿梭其中。它们每天总共要行驶800万英里（约1287万公里），去年一整年，Waymo的虚拟无人车行驶了25亿英里，而实体测试车全年累积的里程，只有300万英里。  
另外，Waymo还在美国加州中央山谷地区的小城默塞德附近建了一个叫做castle的无人驾驶基地，综合了多种路况，利用多种道具建立了一个小型“城市”。